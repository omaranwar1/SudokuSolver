"""
OCR helpers using simple template matching for Sudoku digits.

Approach:
1) Split the straightened binary grid into 9x9 cells.
2) Discard empty cells using pixel coverage.
3) For remaining cells, clear borders, and compare against generated template digits
   using binary IoU plus a hole-count penalty to separate similar shapes (6/8/9).
"""

import os
from pathlib import Path

import cv2
import numpy as np

from scripts.simple_cell_classifier import (  # type: ignore
    overlap_score as sc_overlap_score,
    preprocess_with_steps as sc_preprocess_with_steps,
    scale_image_to_fit as sc_scale_image_to_fit,
    shift_image as sc_shift_image,
)

def _load_templates_from_dir(
    template_dir: str | Path,
    size: int = 50,
    allowed_prefixes: tuple[str, ...] | None = None,
) -> dict[int, list[np.ndarray]]:
    """
    Load digit templates (1-9) from disk. Expects PNGs named like `1_*.png`.

    Returns an empty list for digits with no files found.
    """
    dir_path = Path(template_dir)
    templates: dict[int, list[np.ndarray]] = {d: [] for d in range(1, 10)}

    if not dir_path.exists():
        return templates

    for png in sorted(dir_path.glob("*.png")):
        stem = png.stem
        parts = stem.split("_")
        try:
            digit = int(parts[0])
        except (ValueError, IndexError):
            continue
        if digit not in templates:
            continue
        font_tag = "_".join(parts[1:]) if len(parts) > 1 else ""
        if allowed_prefixes and not any(font_tag.lower().startswith(p.lower()) for p in allowed_prefixes):
            continue
        img = cv2.imread(str(png), cv2.IMREAD_GRAYSCALE)
        if img is None:
            continue
        if img.mean() > 127:
            img = cv2.bitwise_not(img)
        if img.shape != (size, size):
            img = cv2.resize(img, (size, size), interpolation=cv2.INTER_AREA)
        templates[digit].append(img)

    return templates


def build_digit_templates(
    size: int = 50,
    template_dir: str | Path = "digit_templates",
    allowed_prefixes: tuple[str, ...] | None = None,
    augment_strokes: bool = True,
) -> dict[int, list[np.ndarray]]:
    """
    Load digit templates from disk (generated by src/generate_digit_templates.py).
    Falls back to synthetic templates if any digit is missing.

    allowed_prefixes: only use template files whose name after the digit starts
                      with one of these prefixes (case-insensitive).
    augment_strokes: add simple dilated/eroded variants to cover thickness drift.
    """
    templates = _load_templates_from_dir(template_dir, size=size, allowed_prefixes=allowed_prefixes)
    missing = [d for d, imgs in templates.items() if len(imgs) == 0]

    if missing:
        raise ValueError(f"Missing template PNGs for digits: {missing}")

    if augment_strokes:
        kernel = np.ones((2, 2), np.uint8)
        for d, imgs in templates.items():
            augmented: list[np.ndarray] = []
            for img in imgs:
                augmented.append(img)
                augmented.append(cv2.dilate(img, kernel, iterations=1))
                augmented.append(cv2.erode(img, kernel, iterations=1))
            templates[d] = augmented

    return templates


def _count_holes(mask: np.ndarray) -> int:
    """Count holes inside the foreground using contour hierarchy."""
    cnts, hier = cv2.findContours(mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)
    if hier is None:
        return 0
    holes = 0
    for h in hier[0]:
        if h[3] != -1:  # has a parent -> hole
            holes += 1
    return holes


def _template_hole_counts(templates: dict[int, list[np.ndarray]]) -> dict[int, list[int]]:
    """Precompute hole counts for each template variant."""
    return {d: [_count_holes(tmpl) for tmpl in tmpl_list] for d, tmpl_list in templates.items()}


def remove_grid_lines(binary_grid: np.ndarray) -> np.ndarray:
    """
    Remove most grid lines to reduce interference for OCR.

    Works on binary images where digits/lines are white on black.
    """
    h, w = binary_grid.shape
    cell_h, cell_w = h // 9, w // 9

    work = binary_grid.copy()
    if work.mean() > 127:
        work = cv2.bitwise_not(work)

    # Detect horizontal and vertical lines using morphology
    h_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (max(1, cell_w // 2), 1))
    v_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, max(1, cell_h // 2)))

    horiz = cv2.morphologyEx(work, cv2.MORPH_OPEN, h_kernel, iterations=1)
    vert = cv2.morphologyEx(work, cv2.MORPH_OPEN, v_kernel, iterations=1)

    lines = cv2.bitwise_or(horiz, vert)

    # Dilate a little to cover line thickness
    lines = cv2.dilate(lines, np.ones((3, 3), np.uint8), iterations=1)

    digits_only = cv2.bitwise_and(work, cv2.bitwise_not(lines))
    return digits_only


def _extract_digit_from_cell(
    cell: np.ndarray,
    templates: dict[int, list[np.ndarray]],
    min_fill: float = 0.02,
    accept_threshold: float = 0.0,
    min_separation: float = 0.0,
    fallback: bool = False,
    debug: bool = False,
) -> tuple[int, float, np.ndarray | None]:
    """
    Recognize a digit from a single cell image using IoU + hole-aware penalty.

    Returns:
        (digit, score, best_image) where digit=0 means empty cell and best_image is the matched candidate.
    """
    target_size = next(iter(templates.values()))[0].shape[0]

    # Use the same preprocessing as the simple classifier (polarity fix + Otsu + border clear + resize).
    steps = sc_preprocess_with_steps(cell, target_size=target_size)
    binary = steps["border_cleared"]

    # Empty checks (ink, component size/aspect) to reject grid remnants/noise.
    coverage = np.count_nonzero(binary) / binary.size
    if coverage < min_fill:
        if debug:
            print(f"[OCR] empty by coverage={coverage:.4f}")
        return 0, 0.0, None
    if coverage > 0.98:
        if debug:
            print(f"[OCR] empty by high coverage={coverage:.4f}")
        return 0, 0.0, None

    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(binary, connectivity=8)
    if num_labels <= 1:
        if debug:
            print("[OCR] empty: no connected components")
        return 0, 0.0, None

    digit_label = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])
    comp_area = float(stats[digit_label, cv2.CC_STAT_AREA])
    comp_w = int(stats[digit_label, cv2.CC_STAT_WIDTH])
    comp_h = int(stats[digit_label, cv2.CC_STAT_HEIGHT])
    bbox_area = comp_w * comp_h

    min_component_area = 0.01 * binary.size
    if comp_area < min_component_area:
        if debug:
            print(f"[OCR] empty by component area={comp_area/binary.size:.4f}")
        return 0, 0.0, None

    min_bbox_area = 0.025 * binary.size
    if bbox_area < min_bbox_area:
        if debug:
            print(f"[OCR] empty by bbox area={bbox_area/(binary.size):.4f}")
        return 0, 0.0, None

    min_dim = max(4, int(target_size * 0.08))
    if comp_w < min_dim or comp_h < min_dim:
        if debug:
            print(f"[OCR] empty by dimensions w={comp_w}, h={comp_h}")
        return 0, 0.0, None

    aspect_ratio = max(comp_w, comp_h) / max(1, min(comp_w, comp_h))
    if aspect_ratio > 10.0 and comp_area / bbox_area > 0.6:
        # Extremely thin, tall/flat components are likely leftover grid lines.
        if debug:
            print(f"[OCR] empty by aspect={aspect_ratio:.2f}, area={comp_area/binary.size:.4f}")
        return 0, 0.0, None

    # Center the main component on the canvas to reduce alignment drift, but skip if it sits on an edge.
    digit_mask = np.zeros_like(binary)
    digit_mask[labels == digit_label] = 255
    left = stats[digit_label, cv2.CC_STAT_LEFT]
    top = stats[digit_label, cv2.CC_STAT_TOP]
    right = left + comp_w
    bottom = top + comp_h
    touches_edge = left <= 1 or top <= 1 or right >= binary.shape[1] - 2 or bottom >= binary.shape[0] - 2
    if not touches_edge:
        comp_cx = left + comp_w / 2.0
        comp_cy = top + comp_h / 2.0
        canvas_cx = binary.shape[1] / 2.0
        canvas_cy = binary.shape[0] / 2.0
        dx = int(round(canvas_cx - comp_cx))
        dy = int(round(canvas_cy - comp_cy))
        max_shift = int(target_size * 0.35)
        if abs(dx) <= max_shift and abs(dy) <= max_shift:
            M = np.float32([[1, 0, dx], [0, 1, dy]])
            binary = cv2.warpAffine(
                digit_mask,
                M,
                (binary.shape[1], binary.shape[0]),
                flags=cv2.INTER_NEAREST,
                borderValue=0,
            )

    # Generate candidate variants with small shifts and scales to improve alignment.
    scale_deltas = (-3, -2, -1, 0, 1, 2, 3)
    shift_offsets = (-3, -2, -1, 0, 1, 2, 3)
    base_variants: list[np.ndarray] = []
    for delta in scale_deltas:
        scaled = sc_scale_image_to_fit(binary, target_size, delta)
        for dy in shift_offsets:
            for dx in shift_offsets:
                base_variants.append(sc_shift_image(scaled, dx, dy))

    candidates: list[np.ndarray] = []
    for var in base_variants:
        candidates.append(var)
        candidates.append(cv2.bitwise_not(var))

    template_holes = _template_hole_counts(templates)
    per_digit_best = {d: -1.0 for d in range(1, 10)}
    best_digit, best_score = 0, -1.0
    second_best = -1.0
    best_image: np.ndarray | None = None

    for cand in candidates:
        cand_holes = _count_holes(cand)
        for digit, tmpl_list in templates.items():
            hole_list = template_holes[digit]
            for idx, tmpl in enumerate(tmpl_list):
                raw_score = sc_overlap_score(cand, tmpl)
                hole_penalty = 0.12 * abs(cand_holes - hole_list[idx])
                score = max(0.0, raw_score - hole_penalty)

                per_digit_best[digit] = max(per_digit_best[digit], score)
                if score > best_score:
                    second_best = best_score
                    best_digit, best_score = digit, score
                    best_image = cand
                elif score > second_best:
                    second_best = score

    if debug:
        print(f"[OCR] scores: best={best_score:.3f}, second={second_best:.3f}, sep={best_score-second_best:.3f}, fallback={fallback}")

    thresh = accept_threshold
    sep = min_separation
    if best_score < thresh or (best_score - second_best) < sep:
        return 0, best_score, best_image

    return best_digit, best_score, best_image


def resolve_conflicts(board: np.ndarray, scores: np.ndarray, min_score_keep: float = 0.0
                      ) -> tuple[np.ndarray, list[str]]:
    """
    Remove duplicate givens in rows/cols/blocks by keeping only the highest-score hit.

    Returns:
        cleaned_board, list of notes about removed cells
    """
    cleaned = board.copy()
    notes: list[str] = []

    def drop_duplicates(index_list: list[tuple[int, int]], label: str):
        nonlocal cleaned, notes
        values = {}
        for r, c in index_list:
            v = cleaned[r, c]
            if v == 0:
                continue
            values.setdefault(v, []).append((r, c))
        for v, cells in values.items():
            if len(cells) <= 1:
                continue
            keep = max(cells, key=lambda p: scores[p])
            for cell in cells:
                if cell == keep:
                    continue
                if scores[cell] >= min_score_keep:
                    notes.append(f"{label}: dropped duplicate '{v}' at ({cell[0]+1},{cell[1]+1})")
                cleaned[cell] = 0

    # Rows
    for r in range(9):
        idx = [(r, c) for c in range(9)]
        drop_duplicates(idx, f"Row {r+1}")

    # Columns
    for c in range(9):
        idx = [(r, c) for r in range(9)]
        drop_duplicates(idx, f"Col {c+1}")

    # Blocks
    for br in range(3):
        for bc in range(3):
            idx = []
            for r in range(br * 3, br * 3 + 3):
                for c in range(bc * 3, bc * 3 + 3):
                    idx.append((r, c))
            drop_duplicates(idx, f"Block {br+1},{bc+1}")

    return cleaned, notes


def extract_grid_digits(
    binary_grid: np.ndarray,
    templates: dict[int, list[np.ndarray]] | None = None,
    cell_margin: float = 0.0,
    save_cells_dir: str | None = None,
    debug: bool = False,
) -> tuple[np.ndarray, np.ndarray]:
    """
    Extract a 9x9 integer grid (0 = empty) from the straightened binary image.

    Args:
        binary_grid: Final binary grid (digits/lines white on black).
        templates: Optional pre-built templates.
        cell_margin: Fraction of a cell to trim on each side to drop grid lines.
        save_cells_dir: If provided, dump the cropped per-cell images for debugging.
        debug: If True, print rejection reasons/score info.

    Returns:
        board (9x9 ints), scores (9x9 floats correlation confidence)
    """
    if templates is None:
        templates = build_digit_templates()

    # Prepare two views: with grid lines removed, and the raw inverted
    digits_only = remove_grid_lines(binary_grid)
    raw_view = binary_grid.copy()
    if raw_view.mean() > 127:
        raw_view = cv2.bitwise_not(raw_view)

    h, w = digits_only.shape
    cell_h = h // 9
    cell_w = w // 9
    # Ignore a small border inside each cell to avoid grid lines bleeding into OCR
    inner_margin = int(min(cell_h, cell_w) * cell_margin)
    inner_margin = max(0, min(inner_margin, cell_h // 2 - 1, cell_w // 2 - 1))

    if save_cells_dir:
        os.makedirs(save_cells_dir, exist_ok=True)

    board = np.zeros((9, 9), dtype=int)
    scores = np.zeros((9, 9), dtype=float)

    def run_pass(margin: int):
        nonlocal board, scores
        for r in range(9):
            for c in range(9):
                y1, y2 = r * cell_h + margin, (r + 1) * cell_h - margin
                x1, x2 = c * cell_w + margin, (c + 1) * cell_w - margin
                cell1 = digits_only[y1:y2, x1:x2]
                cell2 = raw_view[y1:y2, x1:x2]
                d1, s1, img1 = _extract_digit_from_cell(cell1, templates, fallback=False, debug=debug)
                d2, s2, img2 = _extract_digit_from_cell(cell2, templates, fallback=False, debug=debug)
                if s2 > s1:
                    digit, score, chosen_img = d2, s2, img2
                    chosen_cell = cell2
                else:
                    digit, score, chosen_img = d1, s1, img1
                    chosen_cell = cell1

                # Global confidence floor: treat low scores as empty.
                min_conf = 0.35
                if score < min_conf:
                    digit = 0
                    score = 0.0
                    chosen_img = None

                if board[r, c] == 0 or score > scores[r, c]:
                    board[r, c] = digit
                    scores[r, c] = score
                    if save_cells_dir:
                        to_save = chosen_img if chosen_img is not None else chosen_cell
                        cv2.imwrite(os.path.join(save_cells_dir, f"r{r}_c{c}.png"), to_save)

    run_pass(margin=inner_margin)

    return board, scores


def format_board(board: np.ndarray) -> str:
    """Render the 9x9 board as a human-friendly string."""
    lines = []
    for r, row in enumerate(board):
        parts = []
        for c, val in enumerate(row):
            parts.append(str(val) if val != 0 else ".")
            if c in {2, 5}:
                parts.append("|")
        line = " ".join(parts)
        lines.append(line)
        if r in {2, 5}:
            lines.append("-" * len(line))
    return "\n".join(lines)


def render_solution_on_image(image: np.ndarray, solved: np.ndarray, original: np.ndarray) -> np.ndarray:
    """
    Overlay solved digits on top of the straightened image.

    Given digits (original) are drawn in white, solved digits in green.
    """
    if image.ndim == 2:
        canvas = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
    else:
        canvas = image.copy()

    h, w = canvas.shape[:2]
    cell_h = h // 9
    cell_w = w // 9
    font = cv2.FONT_HERSHEY_SIMPLEX

    for r in range(9):
        for c in range(9):
            val = int(solved[r, c])
            if val == 0:
                continue
            color = (255, 255, 255) if original[r, c] != 0 else (0, 200, 0)
            text = str(val)
            size, _ = cv2.getTextSize(text, font, 0.9, 2)
            x = c * cell_w + (cell_w - size[0]) // 2
            y = r * cell_h + (cell_h + size[1]) // 2
            cv2.putText(canvas, text, (x, y), font, 0.9, color, 2, cv2.LINE_AA)

    return canvas
